import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from urllib.parse import urljoin
import argparse

BASE_URL = "https://openaccess.thecvf.com/"

def get_paper_details(paper_url):
    """
    ä»è®ºæ–‡è¯¦æƒ…é¡µè·å–æ‘˜è¦å’ŒPDF URL
    """
    try:
        response = requests.get(paper_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        # æå–æ‘˜è¦
        abstract_div = soup.find('div', id='abstract')
        abstract = abstract_div.get_text(strip=True) if abstract_div else ""
        
        # ç§»é™¤å‰å¯¼çš„ "Abstract" æ ‡ç­¾
        if abstract.startswith("Abstract"):
            abstract = abstract[len("Abstract"):].strip()
        
        # æå–PDF URL
        pdf_url = ""
        pdf_link = soup.find('a', href=lambda x: x and x.endswith('.pdf'))
        if pdf_link:
            pdf_url = urljoin(BASE_URL, pdf_link['href'])
        
        return abstract, pdf_url

    except Exception as e:
        print(f"    âŒ é”™è¯¯: {e}")
        return None, None

def fix_empty_cells(input_file, output_file, start_year=2013, end_year=2019, dry_run=False):
    """
    ä¿®å¤Excelæ–‡ä»¶ä¸­çš„ç©ºå•å…ƒæ ¼
    
    Args:
        input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
        start_year: å¼€å§‹å¹´ä»½
        end_year: ç»“æŸå¹´ä»½
        dry_run: å¦‚æœä¸ºTrueï¼Œåªæ£€æŸ¥ä¸ä¿®æ”¹
    """
    print("=" * 80)
    print(f"ä¿®å¤ç©ºå•å…ƒæ ¼è„šæœ¬ - {start_year}å¹´è‡³{end_year}å¹´")
    print("=" * 80)
    print()
    
    if dry_run:
        print("âš ï¸  DRY RUN æ¨¡å¼ - åªæ£€æŸ¥ï¼Œä¸ä¿®æ”¹æ–‡ä»¶")
        print()
    
    # è¯»å–æ‰€æœ‰sheet
    df_dict = pd.read_excel(input_file, sheet_name=None)
    
    total_fixed = 0
    total_failed = 0
    sheets_modified = {}
    
    for sheet_name, df in df_dict.items():
        year = int(sheet_name.split('_')[1])
        
        # åªå¤„ç†æŒ‡å®šå¹´ä»½èŒƒå›´
        if year < start_year or year > end_year:
            sheets_modified[sheet_name] = df
            continue
        
        print(f"\n{'='*70}")
        print(f"ğŸ“… å¤„ç† {sheet_name} (å…± {len(df)} ç¯‡è®ºæ–‡)")
        print(f"{'='*70}")
        
        # æ£€æŸ¥ç©ºæ‘˜è¦
        empty_abstract_mask = df['Abstract'].isna() | (df['Abstract'].astype(str).str.strip() == '') | (df['Abstract'].astype(str) == 'nan')
        empty_abstract_count = empty_abstract_mask.sum()
        
        # æ£€æŸ¥ç©ºPDF_URL
        empty_pdf_mask = df['PDF_URL'].isna() | (df['PDF_URL'].astype(str).str.strip() == '') | (df['PDF_URL'].astype(str) == 'nan')
        empty_pdf_count = empty_pdf_mask.sum()
        
        print(f"  å‘ç° {empty_abstract_count} ä¸ªç©ºæ‘˜è¦")
        print(f"  å‘ç° {empty_pdf_count} ä¸ªç©ºPDF_URL")
        
        if empty_abstract_count == 0 and empty_pdf_count == 0:
            print(f"  âœ… æ— éœ€ä¿®å¤")
            sheets_modified[sheet_name] = df
            continue
        
        # æ‰¾å‡ºéœ€è¦ä¿®å¤çš„è¡Œï¼ˆæ‘˜è¦æˆ–PDF_URLä¸ºç©ºï¼‰
        needs_fix_mask = empty_abstract_mask | empty_pdf_mask
        needs_fix_indices = df[needs_fix_mask].index.tolist()
        
        print(f"  éœ€è¦ä¿®å¤ {len(needs_fix_indices)} è¡Œ")
        print()
        
        # åˆ›å»ºå‰¯æœ¬ä»¥ä¾¿ä¿®æ”¹
        df_fixed = df.copy()
        
        for idx, row_idx in enumerate(needs_fix_indices, 1):
            row = df.loc[row_idx]
            title = row['Title']
            url = row['URL']
            
            print(f"  [{idx}/{len(needs_fix_indices)}] ä¿®å¤: {title[:60]}...")
            
            if dry_run:
                print(f"    [DRY RUN] å°†è®¿é—®: {url}")
                continue
            
            # è·å–è¯¦æƒ…
            abstract, pdf_url = get_paper_details(url)
            
            if abstract is not None or pdf_url is not None:
                # æ›´æ–°ç©ºæ‘˜è¦
                if empty_abstract_mask[row_idx] and abstract:
                    df_fixed.at[row_idx, 'Abstract'] = abstract
                    print(f"    âœ… æ‘˜è¦å·²æ›´æ–° ({len(abstract)} å­—ç¬¦)")
                elif empty_abstract_mask[row_idx]:
                    print(f"    âš ï¸  æ‘˜è¦ä»ä¸ºç©º")
                    total_failed += 1
                
                # æ›´æ–°ç©ºPDF_URL
                if empty_pdf_mask[row_idx] and pdf_url:
                    df_fixed.at[row_idx, 'PDF_URL'] = pdf_url
                    print(f"    âœ… PDF_URLå·²æ›´æ–°")
                elif empty_pdf_mask[row_idx]:
                    print(f"    âš ï¸  PDF_URLä»ä¸ºç©º")
                    total_failed += 1
                
                if abstract or pdf_url:
                    total_fixed += 1
            else:
                print(f"    âŒ è·å–å¤±è´¥")
                total_failed += 1
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)
        
        sheets_modified[sheet_name] = df_fixed
    
    # ä¿å­˜ç»“æœ
    if not dry_run:
        print("\n" + "=" * 80)
        print("ğŸ’¾ ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶...")
        print("=" * 80)
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            for sheet_name, df in sheets_modified.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ä¿®å¤ç»Ÿè®¡")
    print("=" * 80)
    print(f"æˆåŠŸä¿®å¤: {total_fixed} å¤„")
    print(f"ä¿®å¤å¤±è´¥: {total_failed} å¤„")
    print()

def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(
        description='ä¿®å¤CVPR Excelæ–‡ä»¶ä¸­çš„ç©ºæ‘˜è¦å’ŒPDFé“¾æ¥',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å…ˆè¿è¡Œdry runæ£€æŸ¥
  python fix_empty_cells.py --input CVPR_xlsx/CVPR_2013_2025.xlsx --dry-run
  
  # ä¿®å¤2013-2019å¹´çš„ç©ºå•å…ƒæ ¼
  python fix_empty_cells.py --input CVPR_xlsx/CVPR_2013_2025.xlsx --output CVPR_xlsx/CVPR_2013_2025_fixed.xlsx
  
  # åªä¿®å¤ç‰¹å®šå¹´ä»½
  python fix_empty_cells.py --input CVPR_xlsx/CVPR_2013_2025.xlsx --output CVPR_xlsx/CVPR_2013_2025_fixed.xlsx --start-year 2014 --end-year 2015
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        default='CVPR_xlsx/CVPR_2013_2025.xlsx',
        help='è¾“å…¥Excelæ–‡ä»¶è·¯å¾„ (é»˜è®¤: CVPR_xlsx/CVPR_2013_2025.xlsx)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='CVPR_xlsx/CVPR_2013_2025_fixed.xlsx',
        help='è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ (é»˜è®¤: CVPR_xlsx/CVPR_2013_2025_fixed.xlsx)'
    )
    
    parser.add_argument(
        '--start-year', '-s',
        type=int,
        default=2013,
        help='å¼€å§‹å¹´ä»½ (é»˜è®¤: 2013)'
    )
    
    parser.add_argument(
        '--end-year', '-e',
        type=int,
        default=2019,
        help='ç»“æŸå¹´ä»½ (é»˜è®¤: 2019)'
    )
    
    parser.add_argument(
        '--dry-run', '-d',
        action='store_true',
        help='åªæ£€æŸ¥ä¸ä¿®æ”¹ (dry runæ¨¡å¼)'
    )
    
    return parser.parse_args()

def main():
    args = parse_arguments()
    
    print(f"é…ç½®:")
    print(f"  è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"  è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"  å¹´ä»½èŒƒå›´: {args.start_year} - {args.end_year}")
    print(f"  Dry Run: {args.dry_run}")
    print()
    
    fix_empty_cells(
        input_file=args.input,
        output_file=args.output,
        start_year=args.start_year,
        end_year=args.end_year,
        dry_run=args.dry_run
    )

if __name__ == "__main__":
    main()
