"""
ä¸»æµç¨‹ - ä¸ºè®ºæ–‡æŸ¥æ‰¾å’ŒéªŒè¯ä»£ç ä»“åº“
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, Optional
import argparse

from config import PAPERS_ROOT_DIR
from utils import (
    get_all_paper_dirs,
    load_paper_data,
    load_code_data,
    save_code_data,
    create_code_data_structure
)
from pdf_extractor import process_paper_pdf
from github_search import search_github_implementations
from repo_validator import validate_repository


def process_single_paper(
    paper_dir: str,
    use_llm: bool = True,
    skip_pdf: bool = False,
    skip_validation: bool = False,
    skip_if_processed: bool = True
) -> Dict:
    """
    å¤„ç†å•ç¯‡è®ºæ–‡çš„å®Œæ•´æµç¨‹
    
    Args:
        paper_dir: è®ºæ–‡ç›®å½•
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM
        skip_pdf: æ˜¯å¦è·³è¿‡ PDF æå–
        skip_validation: æ˜¯å¦è·³è¿‡ä»“åº“éªŒè¯
        skip_if_processed: æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„è®ºæ–‡
        
    Returns:
        å¤„ç†ç»“æœ
    """
    paper_name = os.path.basename(paper_dir)
    start_time = time.time()
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ å¤„ç†è®ºæ–‡: {paper_name}")
    print(f"{'='*80}")
    
    # åŠ è½½è®ºæ–‡æ•°æ®
    paper_data = load_paper_data(paper_dir)
    if not paper_data:
        print("âŒ æ— æ³•åŠ è½½è®ºæ–‡æ•°æ®")
        return {"success": False, "reason": "Cannot load paper data"}
    
    print(f"æ ‡é¢˜: {paper_data.get('title', 'N/A')}")
    print(f"å¹´ä»½: {paper_data.get('year', 'N/A')}")
    
    # åŠ è½½å·²æœ‰çš„ä»£ç æ•°æ®
    existing_code_data = load_code_data(paper_dir)
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
    if skip_if_processed and existing_code_data.get("selected_repo_url"):
        print(f"âœ… å·²æœ‰ä»£ç ä»“åº“: {existing_code_data['selected_repo_url']}")
        if not skip_validation and existing_code_data.get("quality", {}).get("score") is None:
            print("  é‡æ–°éªŒè¯ä»“åº“è´¨é‡...")
        else:
            elapsed = time.time() - start_time
            print(f"â­ï¸  è·³è¿‡å·²å¤„ç†çš„è®ºæ–‡ (è€—æ—¶: {elapsed:.2f}ç§’)")
            return {"success": True, "reason": "Already processed", "data": existing_code_data, "elapsed_time": elapsed}
    
    # åˆ›å»ºä»£ç æ•°æ®ç»“æ„
    code_data = create_code_data_structure()
    
    # ============ é˜¶æ®µ A1: ä» PDF æå–ä»£ç é“¾æ¥ ============
    if not skip_pdf:
        pdf_result = process_paper_pdf(paper_dir, paper_data, use_llm)
        
        if pdf_result["success"]:
            code_data["official_repo_url"] = pdf_result["official_repo_url"]
            code_data["selected_repo_url"] = pdf_result["official_repo_url"]
            code_data["repo_type"] = "official"
            code_data["extraction_source"] = "pdf"
            
            print(f"âœ… ä» PDF æ‰¾åˆ°å®˜æ–¹ä»“åº“: {code_data['official_repo_url']}")
        else:
            print(f"âš ï¸  PDF ä¸­æœªæ‰¾åˆ°ä»£ç é“¾æ¥")
    
    # ============ é˜¶æ®µ A2 & A3: GitHub æœç´¢ ============
    if not code_data["selected_repo_url"]:
        print(f"\n{'â”€'*80}")
        github_result = search_github_implementations(
            paper_data,
            max_results=10,
            use_llm=use_llm
        )
        
        if github_result["success"] and github_result["unofficial_repos"]:
            code_data["unofficial_repo_urls"] = github_result["unofficial_repos"]
            code_data["selected_repo_url"] = github_result["unofficial_repos"][0]
            code_data["repo_type"] = "unofficial"
            code_data["extraction_source"] = "github_search"
            
            print(f"âœ… æ‰¾åˆ°éå®˜æ–¹å®ç°: {code_data['selected_repo_url']}")
        else:
            code_data["repo_type"] = "none_found"
            print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•ä»£ç å®ç°")
    
    # ============ é˜¶æ®µ B: éªŒè¯ä»“åº“è´¨é‡ ============
    if code_data["selected_repo_url"] and not skip_validation:
        print(f"\n{'â”€'*80}")
        validation_result = validate_repository(
            code_data["selected_repo_url"],
            paper_data,
            use_llm=use_llm
        )
        
        code_data["quality"] = {
            "score": validation_result.get("score"),
            "is_meaningful": validation_result.get("is_meaningful"),
            "reason": validation_result.get("reason", ""),
            "reasons": validation_result.get("reasons", [])
        }
        
        if validation_result.get("is_meaningful"):
            print(f"âœ… ä»“åº“æœ‰æ„ä¹‰ (åˆ†æ•°: {validation_result.get('score', 'N/A')})")
        else:
            print(f"âŒ ä»“åº“æ— æ„ä¹‰: {validation_result.get('reason')}")
            # æ¸…é™¤æ— æ„ä¹‰çš„ä»“åº“
            code_data["selected_repo_url"] = None
            code_data["repo_type"] = "none_meaningful"
    
    # ä¿å­˜ç»“æœ
    code_data["processed_at"] = datetime.now().isoformat()
    save_code_data(paper_dir, code_data)
    
    elapsed = time.time() - start_time
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° {os.path.join(paper_dir, 'github_links.json')}")
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f}ç§’ ({elapsed/60:.2f}åˆ†é’Ÿ)")
    
    return {
        "success": True,
        "data": code_data,
        "elapsed_time": elapsed
    }


def process_all_papers(
    root_dir: str = PAPERS_ROOT_DIR,
    use_llm: bool = True,
    skip_pdf: bool = False,
    skip_validation: bool = False,
    limit: Optional[int] = None,
    resume: bool = True
):
    """
    å¤„ç†æ‰€æœ‰è®ºæ–‡
    
    Args:
        root_dir: è®ºæ–‡æ ¹ç›®å½•
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM
        skip_pdf: æ˜¯å¦è·³è¿‡ PDF æå–
        skip_validation: æ˜¯å¦è·³è¿‡ä»“åº“éªŒè¯
        limit: é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        resume: æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„è®ºæ–‡
    """
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†è®ºæ–‡")
    print(f"{'='*80}")
    print(f"æ ¹ç›®å½•: {root_dir}")
    print(f"ä½¿ç”¨ LLM: {use_llm}")
    print(f"è·³è¿‡ PDF: {skip_pdf}")
    print(f"è·³è¿‡éªŒè¯: {skip_validation}")
    print(f"é™åˆ¶æ•°é‡: {limit if limit else 'æ— é™åˆ¶'}")
    print(f"æ¢å¤æ¨¡å¼: {resume}")
    
    # è·å–æ‰€æœ‰è®ºæ–‡ç›®å½•
    paper_dirs = get_all_paper_dirs(root_dir)
    total = len(paper_dirs)
    
    if limit:
        paper_dirs = paper_dirs[:limit]
        total = len(paper_dirs)
    
    print(f"\næ‰¾åˆ° {total} ç¯‡è®ºæ–‡å¾…å¤„ç†\n")
    
    # ç»Ÿè®¡
    stats = {
        "total": total,
        "processed": 0,
        "skipped": 0,
        "found_official": 0,
        "found_unofficial": 0,
        "not_found": 0,
        "meaningful": 0,
        "not_meaningful": 0,
        "errors": 0
    }
    
    start_time = time.time()
    
    for i, paper_dir in enumerate(paper_dirs, 1):
        paper_name = os.path.basename(paper_dir)
        paper_start_time = time.time()
        print(f"\n[{i}/{total}] {paper_name}")
        
        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        if resume:
            existing = load_code_data(paper_dir)
            if existing.get("processed_at"):
                paper_elapsed = time.time() - paper_start_time
                print(f"â­ï¸  å·²å¤„ç†ï¼Œè·³è¿‡ (è€—æ—¶: {paper_elapsed:.2f}ç§’)")
                stats["skipped"] += 1
                continue
        
        try:
            result = process_single_paper(
                paper_dir,
                use_llm=use_llm,
                skip_pdf=skip_pdf,
                skip_validation=skip_validation,
                skip_if_processed=resume
            )
            
            if result["success"]:
                paper_elapsed = result.get("elapsed_time", time.time() - paper_start_time)
                print(f"\nâ±ï¸  æœ¬ç¯‡è€—æ—¶: {paper_elapsed:.2f}ç§’ ({paper_elapsed/60:.2f}åˆ†é’Ÿ)")
                stats["processed"] += 1
                
                data = result.get("data", {})
                repo_type = data.get("repo_type")
                
                if repo_type == "official":
                    stats["found_official"] += 1
                elif repo_type == "unofficial":
                    stats["found_unofficial"] += 1
                elif repo_type in ["none_found", "none_meaningful"]:
                    stats["not_found"] += 1
                
                if data.get("quality", {}).get("is_meaningful"):
                    stats["meaningful"] += 1
                elif data.get("quality", {}).get("is_meaningful") is False:
                    stats["not_meaningful"] += 1
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            stats["errors"] += 1
            import traceback
            traceback.print_exc()
        
        # æ‰“å°è¿›åº¦
        elapsed = time.time() - start_time
        processed_count = i - stats["skipped"]
        avg_time = elapsed / processed_count if processed_count > 0 else 0
        remaining = (total - i) * avg_time
        
        print(f"\nğŸ“Š è¿›åº¦: {i}/{total} | "
              f"å·²å¤„ç†: {stats['processed']} | "
              f"è·³è¿‡: {stats['skipped']} | "
              f"é”™è¯¯: {stats['errors']}")
        print(f"â±ï¸  å¹³å‡è€—æ—¶: {avg_time:.2f}ç§’/ç¯‡ | å·²ç”¨æ—¶é—´: {elapsed/60:.1f}åˆ†é’Ÿ | é¢„è®¡å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")
    
    # æœ€ç»ˆç»Ÿè®¡
    total_elapsed = time.time() - start_time
    print(f"\n{'='*80}")
    print(f"âœ… å¤„ç†å®Œæˆ")
    print(f"{'='*80}")
    print(f"æ€»æ•°: {stats['total']}")
    print(f"å·²å¤„ç†: {stats['processed']}")
    print(f"è·³è¿‡: {stats['skipped']}")
    print(f"é”™è¯¯: {stats['errors']}")
    print(f"\nä»£ç æŸ¥æ‰¾ç»“æœ:")
    print(f"  æ‰¾åˆ°å®˜æ–¹ä»“åº“: {stats['found_official']}")
    print(f"  æ‰¾åˆ°éå®˜æ–¹ä»“åº“: {stats['found_unofficial']}")
    print(f"  æœªæ‰¾åˆ°: {stats['not_found']}")
    print(f"\nä»“åº“è´¨é‡:")
    print(f"  æœ‰æ„ä¹‰: {stats['meaningful']}")
    print(f"  æ— æ„ä¹‰: {stats['not_meaningful']}")
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_elapsed:.2f}ç§’ ({total_elapsed/60:.1f}åˆ†é’Ÿ)")
    if stats['processed'] > 0:
        print(f"â±ï¸  å¹³å‡è€—æ—¶: {total_elapsed/stats['processed']:.2f}ç§’/ç¯‡")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸º CVF è®ºæ–‡æŸ¥æ‰¾å’ŒéªŒè¯ä»£ç ä»“åº“",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¤„ç†æ‰€æœ‰è®ºæ–‡ï¼ˆä½¿ç”¨ LLMï¼‰
  python main.py
  
  # åªå¤„ç†å‰ 10 ç¯‡ï¼ˆæµ‹è¯•ï¼‰
  python main.py --limit 10
  
  # ä¸ä½¿ç”¨ LLMï¼ˆä»…è§„åˆ™è¿‡æ»¤ï¼‰
  python main.py --no-llm
  
  # è·³è¿‡ PDF æå–ï¼ˆåªåš GitHub æœç´¢ï¼‰
  python main.py --skip-pdf
  
  # åªæŸ¥æ‰¾ä»£ç ï¼Œä¸éªŒè¯è´¨é‡
  python main.py --skip-validation
  
  # å¤„ç†å•ç¯‡è®ºæ–‡
  python main.py --single "CVPR/2024/Paper Title"
        """
    )
    
    parser.add_argument(
        "--root-dir",
        default=PAPERS_ROOT_DIR,
        help=f"è®ºæ–‡æ ¹ç›®å½• (é»˜è®¤: {PAPERS_ROOT_DIR})"
    )
    
    parser.add_argument(
        "--single",
        type=str,
        help="åªå¤„ç†å•ç¯‡è®ºæ–‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼Œå¦‚ 'CVPR/2024/Paper Title'ï¼‰"
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        help="é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"
    )
    
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="ä¸ä½¿ç”¨ LLMï¼ˆä»…è§„åˆ™è¿‡æ»¤ï¼‰"
    )
    
    parser.add_argument(
        "--skip-pdf",
        action="store_true",
        help="è·³è¿‡ PDF æå–"
    )
    
    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="è·³è¿‡ä»“åº“éªŒè¯"
    )
    
    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="ä¸è·³è¿‡å·²å¤„ç†çš„è®ºæ–‡"
    )
    
    args = parser.parse_args()
    
    # å•ç¯‡è®ºæ–‡æ¨¡å¼
    if args.single:
        paper_dir = os.path.join(args.root_dir, args.single)
        if not os.path.exists(paper_dir):
            print(f"âŒ è®ºæ–‡ç›®å½•ä¸å­˜åœ¨: {paper_dir}")
            sys.exit(1)
        
        process_single_paper(
            paper_dir,
            use_llm=not args.no_llm,
            skip_pdf=args.skip_pdf,
            skip_validation=args.skip_validation,
            skip_if_processed=not args.no_resume
        )
    else:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        process_all_papers(
            root_dir=args.root_dir,
            use_llm=not args.no_llm,
            skip_pdf=args.skip_pdf,
            skip_validation=args.skip_validation,
            limit=args.limit,
            resume=not args.no_resume
        )


if __name__ == "__main__":
    main()
